{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mgc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek546/music-genre-classification/blob/main/mgc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SwzjFUiOq5p"
      },
      "source": [
        "%cd \"/content/drive/My Drive/samsung\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIV9jWAc3BXh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf7a2df7-0cb6-4727-afed-b05d18543f4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKHi-scaVQ4R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "d2ba3ca0-60b3-4f55-a312-9d2c834d3f09"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  8 11:40:35 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    25W /  75W |   7353MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJY9kvwhdy8p"
      },
      "source": [
        " \n",
        "#!/usr/bin/env python\n",
        " \n",
        "import logging\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import xgboost as xgb\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from sklearn.svm import SVC\n",
        "from keras.utils import to_categorical\n",
        " \n",
        " \n",
        "train_X = np.load(\"/content/drive/My Drive/samsung/rb1/mfe6_train_input1.npy\")\n",
        "train_Y = np.load(\"/content/drive/My Drive/samsung/rb1/mfe6_train_target1.npy\")\n",
        "dev_X=np.load(\"/content/drive/My Drive/samsung/rb1/mfe6_validation_input1.npy\")\n",
        "dev_Y=np.load(\"/content/drive/My Drive/samsung/rb1/mfe6_validation_target1.npy\")\n",
        "test_X=np.load(\"/content/drive/My Drive/samsung/rb1/mfe6_test_input1.npy\")\n",
        "test_Y=np.load(\"/content/drive/My Drive/samsung/rb1/mfe6_test_target1.npy\")\n",
        " \n",
        "train_X = tf.convert_to_tensor(train_X,dtype = tf.float64)\n",
        "train_Y = tf.convert_to_tensor(train_Y,dtype = tf.float64)\n",
        "dev_X = tf.convert_to_tensor(dev_X,dtype = tf.float64)\n",
        "dev_Y = tf.convert_to_tensor(dev_Y,dtype = tf.float64)\n",
        "test_X = tf.convert_to_tensor(test_X,dtype = tf.float64)\n",
        "test_Y = tf.convert_to_tensor(test_Y,dtype = tf.float64)\n",
        "print(train_X.shape)\n",
        "input_shape = (train_X.shape[1], train_X.shape[2],train_X.shape[3])\n",
        "print(\"Build LSTM RNN model ...\")\n",
        "model = Sequential()\n",
        " \n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(128,(3,3),activation='relu',input_shape=input_shape,padding='same'))\n",
        "model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        " \n",
        "model.add(keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=input_shape,padding='same'))\n",
        "model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        " \n",
        "model.add(keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=input_shape,padding='same'))\n",
        "model.add(keras.layers.MaxPool2D((2,4),strides=(2,2),padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        " \n",
        "model.add(keras.layers.Conv2D(32,(2,2),activation='relu',input_shape=input_shape,padding='same'))\n",
        "model.add(keras.layers.MaxPool2D((2,4),strides=(2,2),padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        " \n",
        "model.add(keras.layers.Flatten())\n",
        "#model.add(keras.layers.Dense(2048, activation= 'relu'))\n",
        "#model.add(keras.layers.Dropout(0.8))\n",
        "model.add(keras.layers.Dense(1024, activation= 'relu'))\n",
        "model.add(keras.layers.Dropout(0.7))\n",
        "model.add(keras.layers.Dense(512, activation= 'relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(256, activation= 'relu'))\n",
        "model.add(keras.layers.Dropout(0.35))\n",
        "model.add(keras.layers.Dense(128, activation= 'relu'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "#model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "optimerz = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimerz,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "model.fit(train_X,train_Y,\n",
        "          validation_data=(dev_X,dev_Y), epochs= 100)\n",
        "test_accuracy= model.evaluate(test_X,test_Y,verbose=1)\n",
        "print(\"Accuracy: \".format(test_accuracy))\n",
        "print(test_accuracy)\n",
        "print(\"Training ...\")\n",
        "print(model.summary())\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        " \n",
        " \n",
        "# Creates a HDF5 file 'lstm_genre_classifier.h5'\n",
        "model_filename = \"/content/drive/My Drive/samsung/rb1/ch.hdf5\"\n",
        " \n",
        "print(\"\\nSaving model: \" + model_filename)\n",
        "model.save(model_filename)\n",
        "print(\"creating .json file....\")\n",
        "model_json = model.to_json()\n",
        "f = Path(\"/content/drive/My Drive/samsung/rb1/ch.json\")\n",
        "f.write_text(model_json)\n",
        "with open(\"model_new.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kSR6Wh2crGG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9YObOXMc2QW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEuRDMwhc2qK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xmmka06cvMr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2c428fd-769c-4081-df48-1f2eb0e5b149"
      },
      "source": [
        "\"An example of predicting a music genre from a custom audio file\"\n",
        "import librosa\n",
        "import logging\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras.optimizers import Adam\n",
        " # local python class with Audio feature extraction and genre list\n",
        " \n",
        "# set logging level\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "genre_list = [\n",
        "        \"blues\",\n",
        "        \"classical\",\n",
        "        \"country\",\n",
        "        \"disco\",\n",
        "        \"hiphop\",\n",
        "        \"jazz\",\n",
        "        \"metal\",\n",
        "        \"pop\",\n",
        "        \"reggae\",\n",
        "        \"rock\"\n",
        "    ]\n",
        " \n",
        "def load_model(model_path, weights_path):\n",
        "    \"Load the trained LSTM model from directory for genre classification\"\n",
        "    with open(model_path, \"r\") as model_file:\n",
        "        trained_model = tf.keras.models.model_from_json(model_file.read())\n",
        "    trained_model.load_weights(weights_path)\n",
        "    optimerz = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    trained_model.compile(\n",
        "        optimizer=optimerz,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy']\n",
        "    )\n",
        "    return trained_model\n",
        " \n",
        " \n",
        "def extract_audio_features1(file,j):\n",
        "    \"Extract audio features from an audio file for genre classification\"\n",
        "    timeseries_length = 128\n",
        "    features = np.zeros(\n",
        "        (1,timeseries_length,128,1), dtype=np.float64\n",
        "        )\n",
        " \n",
        "    y, sr = librosa.load(file,offset=j*3,duration=6)\n",
        "    \n",
        "    spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "    spect = librosa.power_to_db(spect, ref=np.max)\n",
        "    if spect.shape[1] != 128:\n",
        "         spect.resize(128,128, refcheck=False)\n",
        "    features[0,:,0:128,0] = spect\n",
        "    return features\n",
        "def extract_audio_features2(file,j):\n",
        "    \"Extract audio features from an audio file for genre classification\"\n",
        "    timeseries_length = 128\n",
        "    features = np.zeros(\n",
        "        (1,timeseries_length,512,1), dtype=np.float64\n",
        "        )\n",
        " \n",
        "    y, sr = librosa.load(file,offset=j*3,duration=6)\n",
        "    \n",
        "    X = librosa.stft(y)\n",
        "    X = librosa.amplitude_to_db(abs(X))\n",
        "    if X.shape[1] != 512:\n",
        "         X.resize(128,512, refcheck=False)\n",
        "    features[0,:,0:512,0] = X\n",
        "    return features\n",
        "def extract_audio_features3(file,j):\n",
        "    \"Extract audio features from an audio file for genre classification\"\n",
        "    timeseries_length = 128\n",
        "    features = np.zeros(\n",
        "        (1,timeseries_length,20,1), dtype=np.float64\n",
        "        )\n",
        " \n",
        "    y, sr = librosa.load(file,offset=j*3,duration=6)\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "                y=y, sr=sr, hop_length=1024, n_mfcc=20\n",
        "            )\n",
        "    spectral_center = librosa.feature.spectral_centroid(\n",
        "                y=y, sr=sr, hop_length=1024\n",
        "            )\n",
        "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=1024)\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(\n",
        "                y=y, sr=sr, hop_length=1024\n",
        "            )\n",
        "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)\n",
        "    features[0, :, 0:20,0] = mfcc.T[0:128,:]\n",
        "    \n",
        "    return features\n",
        " \n",
        "def get_genre(model1,model2,model3,music_path):\n",
        "    \"Predict genre of music using a trained model\"\n",
        "    A=[]\n",
        "    for j in range(9):\n",
        "      prediction = model1.predict(extract_audio_features1(music_path,j))\n",
        "      predict_genre = genre_list[np.argmax(prediction)]\n",
        "      A.append(predict_genre)\n",
        "      #print(predict_genre)\n",
        "    for i in range(9):\n",
        "      prediction = model2.predict(extract_audio_features2(music_path,i))\n",
        "      predict_genre = genre_list[np.argmax(prediction)]\n",
        "      #A.append(predict_genre)\n",
        "      #print(predict_genre)\n",
        "    \n",
        "    #for k in range(9):\n",
        "     # prediction = model3.predict(extract_audio_features3(music_path,k))\n",
        "     # predict_genre = genre_list[np.argmax(prediction)] \n",
        "      \n",
        "      \n",
        "      #A.append(predict_genre)\n",
        "      #print(predict_genre)\n",
        "    new_list = sorted(A, key = A.count, reverse=True)\n",
        "    return new_list[0]\n",
        " \n",
        " \n",
        "c = 0\n",
        "co = 0\n",
        "A = []\n",
        "B = []\n",
        "history = (A,B)\n",
        " \n",
        "dict_1 = history\n",
        " \n",
        "if __name__ == \"__main__\":\n",
        "    import pathlib\n",
        "    import os\n",
        "    path = \"/content/drive/My Drive/samsung/test1/\"\n",
        "    data_dir = pathlib.Path(path)\n",
        "    K = list(data_dir.glob(\"*\"))\n",
        "    MODEL1 = load_model(\"/content/drive/My Drive/samsung/rb1/dm6.json\", \"/content/drive/My Drive/samsung/rb1/dm6.hdf5\")\n",
        "    MODEL2 = load_model(\"/content/drive/My Drive/samsung/6d/ds6.json\", \"/content/drive/My Drive/samsung/6d/ds6.hdf5\")\n",
        "    MODEL3 = load_model(\"/content/drive/My Drive/samsung/6d/mf6.json\", \"/content/drive/My Drive/samsung/6d/mf6.hdf5\")\n",
        "    for i in range(len(K)):\n",
        "        co=co+1\n",
        "        p1 = str(K[i])\n",
        "        GENRE = get_genre(MODEL1,MODEL2,MODEL3,p1)\n",
        "        k = str(K[i])\n",
        "        m1 = os.path.splitext(k)\n",
        "        m2 = os.path.split(m1[0])\n",
        "        B.append(\"Model predict: {}\".format(m2[1][:-6]))\n",
        "        A.append(\"Model predict: {}\".format(GENRE))\n",
        "        if A[i]==B[i]:\n",
        "            c=c+1\n",
        "        print(\"Model predict: \"+GENRE+\" Actual model is \"+m2[1][:-6])\n",
        " \n",
        "import pandas as pd\n",
        "df1 = pd.DataFrame.from_dict(dict_1)\n",
        "print(\"Accuracy of the model\")\n",
        "print(c/co)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model predict: blues Actual model is blues\n",
            "Model predict: jazz Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: rock Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: disco Actual model is blues\n",
            "Model predict: jazz Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: jazz Actual model is blues\n",
            "Model predict: reggae Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: rock Actual model is blues\n",
            "Model predict: jazz Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: jazz Actual model is blues\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: jazz Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: rock Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: blues Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: blues Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: blues Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: country Actual model is country\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: hiphop Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: rock Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: hiphop Actual model is disco\n",
            "Model predict: reggae Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: reggae Actual model is disco\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: blues Actual model is disco\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: pop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: country Actual model is jazz\n",
            "Model predict: rock Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: pop Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: classical Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: classical Actual model is jazz\n",
            "Model predict: classical Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: hiphop Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: blues Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: rock Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: jazz Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: blues Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: reggae Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: hiphop Actual model is reggae\n",
            "Model predict: hiphop Actual model is reggae\n",
            "Model predict: jazz Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: blues Actual model is reggae\n",
            "Model predict: hiphop Actual model is reggae\n",
            "Model predict: hiphop Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: disco Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: disco Actual model is reggae\n",
            "Model predict: metal Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: classical Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: hiphop Actual model is rock\n",
            "Model predict: disco Actual model is rock\n",
            "Model predict: country Actual model is rock\n",
            "Model predict: country Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: metal Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: blues Actual model is rock\n",
            "Model predict: reggae Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: jazz Actual model is rock\n",
            "Model predict: blues Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: rock Actual model is rock\n",
            "Model predict: metal Actual model is rock\n",
            "Model predict: blues Actual model is blues\n",
            "Model predict: classical Actual model is classical\n",
            "Model predict: country Actual model is country\n",
            "Model predict: disco Actual model is disco\n",
            "Model predict: hiphop Actual model is hiphop\n",
            "Model predict: jazz Actual model is jazz\n",
            "Model predict: metal Actual model is metal\n",
            "Model predict: pop Actual model is pop\n",
            "Model predict: reggae Actual model is reggae\n",
            "Model predict: blues Actual model is rock\n",
            "Accuracy of the model\n",
            "0.7652173913043478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj70TXlbiOl5"
      },
      "source": [
        "import librosa\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class wor:\n",
        "\n",
        "    \"Music audio features for genre classification\"\n",
        "    hop_length = None\n",
        "    genre_list = [\n",
        "        \"blues\",\n",
        "        \"classical\",\n",
        "        \"country\",\n",
        "        \"disco\",\n",
        "        \"hiphop\",\n",
        "        \"jazz\",\n",
        "        \"metal\",\n",
        "        \"pop\",\n",
        "        \"reggae\",\n",
        "        \"rock\"\n",
        "    ]\n",
        "\n",
        "    dir_trainfolder = \"/content/drive/My Drive/samsung/train\"\n",
        "    dir_devfolder = \"/content/drive/My Drive/samsung/validation\"\n",
        "    dir_testfolder = \"/content/drive/My Drive/samsung/test\"\n",
        "    dir_all_files = \"/content/drive/My Drive/samsung\"\n",
        "\n",
        "    train_X_preprocessed_data = \"/content/drive/My Drive/samsung/mf6_train_input1.npy\"\n",
        "    train_Y_preprocessed_data = \"/content/drive/My Drive/samsung/mf6_train_target1.npy\"\n",
        "    dev_X_preprocessed_data = \"/content/drive/My Drive/samsung/mf6_validation_input1.npy\"\n",
        "    dev_Y_preprocessed_data = \"/content/drive/My Drive/samsung/mf6_validation_target1.npy\"\n",
        "    test_X_preprocessed_data = \"/content/drive/My Drive/samsung/mf6_test_input1.npy\"\n",
        "    test_Y_preprocessed_data = \"/content/drive/My Drive/samsung/mf6_test_target1.npy\"\n",
        "    train_X = train_Y = None\n",
        "    dev_X = dev_Y = None\n",
        "    test_X = test_Y = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.hop_length = 1024\n",
        "\n",
        "        self.timeseries_length_list = []\n",
        "        self.trainfiles_list = self.path_to_audiofiles(self.dir_trainfolder)\n",
        "        self.devfiles_list = self.path_to_audiofiles(self.dir_devfolder)\n",
        "        self.testfiles_list = self.path_to_audiofiles(self.dir_testfolder)\n",
        "\n",
        "        self.all_files_list = []\n",
        "        self.all_files_list.extend(self.trainfiles_list)\n",
        "        self.all_files_list.extend(self.devfiles_list)\n",
        "        self.all_files_list.extend(self.testfiles_list)\n",
        "\n",
        "        # compute minimum timeseries length, slow to compute, caching pre-computed value of 1290\n",
        "        # self.precompute_min_timeseries_len()\n",
        "        # print(\"min(self.timeseries_length_list) ==\" + str(min(self.timeseries_length_list)))\n",
        "        # self.timeseries_length = min(self.timeseries_length_list)\n",
        "\n",
        "        self.timeseries_length = (\n",
        "            128\n",
        "        )   # sequence length == 128, default fftsize == 2048 & hop == 512 @ SR of 22050\n",
        "        #  equals 128 overlapped windows that cover approx ~3.065 seconds of audio, which is a bit small!\n",
        "\n",
        "    def load_preprocess_data(self):\n",
        "        print(\"[DEBUG] total number of files: \" + str(len(self.timeseries_length_list)))\n",
        "\n",
        "        # Training set\n",
        "        self.train_X, self.train_Y = self.extract_audio_features(self.trainfiles_list)\n",
        "        with open(self.train_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.train_X)\n",
        "        with open(self.train_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.train_Y = self.one_hot(self.train_Y)\n",
        "            np.save(f, self.train_Y)\n",
        "\n",
        "        # Validation set\n",
        "        self.dev_X, self.dev_Y = self.extract_audio_features(self.devfiles_list)\n",
        "        with open(self.dev_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.dev_X)\n",
        "        with open(self.dev_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.dev_Y = self.one_hot(self.dev_Y)\n",
        "            np.save(f, self.dev_Y)\n",
        "\n",
        "        # Test set\n",
        "        self.test_X, self.test_Y = self.extract_audio_features(self.testfiles_list)\n",
        "        with open(self.test_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.test_X)\n",
        "        with open(self.test_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.test_Y = self.one_hot(self.test_Y)\n",
        "            np.save(f, self.test_Y)\n",
        "\n",
        "    def load_deserialize_data(self):\n",
        "\n",
        "        self.train_X = np.load(self.train_X_preprocessed_data)\n",
        "        self.train_Y = np.load(self.train_Y_preprocessed_data)\n",
        "\n",
        "        self.dev_X = np.load(self.dev_X_preprocessed_data)\n",
        "        self.dev_Y = np.load(self.dev_Y_preprocessed_data)\n",
        "\n",
        "        self.test_X = np.load(self.test_X_preprocessed_data)\n",
        "        self.test_Y = np.load(self.test_Y_preprocessed_data)\n",
        "    \n",
        "\n",
        "    def precompute_min_timeseries_len(self):\n",
        "        for file in self.all_files_list:\n",
        "            print(\"Loading \" + str(file))\n",
        "            y, sr = librosa.load(file)\n",
        "            self.timeseries_length_list.append(math.ceil(len(y) / self.hop_length))\n",
        "\n",
        "    def extract_audio_features(self, list_of_audiofiles):\n",
        "\n",
        "        features = np.zeros(\n",
        "        (len(list_of_audiofiles)*9,self.timeseries_length,40,1), dtype=np.float64\n",
        "        )\n",
        "        target = []\n",
        "        c=0\n",
        "        for i, file in enumerate(list_of_audiofiles):\n",
        "          for j in range(9):\n",
        "            y, sr = librosa.load(file,offset= j*3 ,duration=6)\n",
        "            mfcc = librosa.feature.mfcc(\n",
        "                y=y, sr=sr, hop_length=self.hop_length, n_mfcc=20\n",
        "            )\n",
        "            spectral_center = librosa.feature.spectral_centroid(\n",
        "                y=y, sr=sr, hop_length=self.hop_length\n",
        "            )\n",
        "            chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=self.hop_length)\n",
        "            spectral_contrast = librosa.feature.spectral_contrast(\n",
        "                y=y, sr=sr, hop_length=self.hop_length\n",
        "            )\n",
        "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "            zcr = librosa.feature.zero_crossing_rate(y)\n",
        "            X = librosa.stft(y)\n",
        "            X = librosa.amplitude_to_db(abs(X))\n",
        "            spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "            spect = librosa.power_to_db(spect, ref=np.max)\n",
        "            if spect.shape[1] != 128:\n",
        "                spect.resize(128,128, refcheck=False)\n",
        "            if X.shape[1] != 128:\n",
        "               X.resize((128,128), refcheck=False)\n",
        "            splits = re.split(\"[ .]\", file)\n",
        "            genre = re.split(\"[ /]\", splits[1])[3]\n",
        "            target.append(genre)\n",
        "            print(genre)\n",
        "            k=0\n",
        "            for e in mfcc:\n",
        "             features[c, :, k,0]= np.mean(e)\n",
        "             k=k+1\n",
        "             features[c, :, k,0]= np.std(e)\n",
        "             k=k+1\n",
        "            \n",
        "            c=c+1\n",
        "            print(\n",
        "                \"Extracted features audio track %i of %i.\"\n",
        "                % (c + 1, len(list_of_audiofiles)*9)\n",
        "            )\n",
        "        return features, np.expand_dims(np.asarray(target), axis=1)\n",
        "\n",
        "    def one_hot(self, Y_genre_strings):\n",
        "        y_one_hot = np.zeros((Y_genre_strings.shape[0],10))\n",
        "        for i, genre_string in enumerate(Y_genre_strings):\n",
        "            index = self.genre_list.index(genre_string)\n",
        "            y_one_hot[i,index] = 1 \n",
        "        return y_one_hot\n",
        "\n",
        "    @staticmethod\n",
        "    def path_to_audiofiles(dir_folder):\n",
        "        list_of_audio = []\n",
        "        for file in os.listdir(dir_folder):\n",
        "            if file.endswith(\".au\"):\n",
        "                directory = \"%s/%s\" % (dir_folder, file)\n",
        "                list_of_audio.append(directory)\n",
        "        return list_of_audio\n",
        "        \n",
        "gen=wor()\n",
        "gen.load_preprocess_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFfJPZSsU8vM"
      },
      "source": [
        "import librosa\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class wor:\n",
        "\n",
        "    \"Music audio features for genre classification\"\n",
        "    hop_length = None\n",
        "    genre_list = [\n",
        "        \"blues\",\n",
        "        \"classical\",\n",
        "        \"country\",\n",
        "        \"disco\",\n",
        "        \"hiphop\",\n",
        "        \"jazz\",\n",
        "        \"metal\",\n",
        "        \"pop\",\n",
        "        \"reggae\",\n",
        "        \"rock\"\n",
        "    ]\n",
        "\n",
        "    dir_trainfolder = \"/content/drive/My Drive/samsung/train\"\n",
        "    dir_devfolder = \"/content/drive/My Drive/samsung/validation\"\n",
        "    dir_testfolder = \"/content/drive/My Drive/samsung/test\"\n",
        "    dir_all_files = \"/content/drive/My Drive/samsung\"\n",
        "\n",
        "    train_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dse6_train_input1.npy\"\n",
        "    train_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dse6_train_target1.npy\"\n",
        "    dev_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dse6_validation_input1.npy\"\n",
        "    dev_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dse6_validation_target1.npy\"\n",
        "    test_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dse6_test_input1.npy\"\n",
        "    test_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dse6_test_target1.npy\"\n",
        "    train_X = train_Y = None\n",
        "    dev_X = dev_Y = None\n",
        "    test_X = test_Y = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.hop_length = 1024\n",
        "\n",
        "        self.timeseries_length_list = []\n",
        "        self.trainfiles_list = self.path_to_audiofiles(self.dir_trainfolder)\n",
        "        self.devfiles_list = self.path_to_audiofiles(self.dir_devfolder)\n",
        "        self.testfiles_list = self.path_to_audiofiles(self.dir_testfolder)\n",
        "\n",
        "        self.all_files_list = []\n",
        "        self.all_files_list.extend(self.trainfiles_list)\n",
        "        self.all_files_list.extend(self.devfiles_list)\n",
        "        self.all_files_list.extend(self.testfiles_list)\n",
        "\n",
        "        # compute minimum timeseries length, slow to compute, caching pre-computed value of 1290\n",
        "        # self.precompute_min_timeseries_len()\n",
        "        # print(\"min(self.timeseries_length_list) ==\" + str(min(self.timeseries_length_list)))\n",
        "        # self.timeseries_length = min(self.timeseries_length_list)\n",
        "\n",
        "        self.timeseries_length = (\n",
        "            128\n",
        "        )   # sequence length == 128, default fftsize == 2048 & hop == 512 @ SR of 22050\n",
        "        #  equals 128 overlapped windows that cover approx ~3.065 seconds of audio, which is a bit small!\n",
        "\n",
        "    def load_preprocess_data(self):\n",
        "        print(\"[DEBUG] total number of files: \" + str(len(self.timeseries_length_list)))\n",
        "\n",
        "        # Training set\n",
        "        self.train_X, self.train_Y = self.extract_audio_features(self.trainfiles_list)\n",
        "        with open(self.train_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.train_X)\n",
        "        with open(self.train_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.train_Y = self.one_hot(self.train_Y)\n",
        "            np.save(f, self.train_Y)\n",
        "\n",
        "        # Validation set\n",
        "        self.dev_X, self.dev_Y = self.extract_audio_features(self.devfiles_list)\n",
        "        with open(self.dev_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.dev_X)\n",
        "        with open(self.dev_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.dev_Y = self.one_hot(self.dev_Y)\n",
        "            np.save(f, self.dev_Y)\n",
        "\n",
        "        # Test set\n",
        "        self.test_X, self.test_Y = self.extract_audio_features(self.testfiles_list)\n",
        "        with open(self.test_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.test_X)\n",
        "        with open(self.test_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.test_Y = self.one_hot(self.test_Y)\n",
        "            np.save(f, self.test_Y)\n",
        "\n",
        "    def load_deserialize_data(self):\n",
        "        \n",
        "        self.train_X = np.load(self.train_X_preprocessed_data)\n",
        "        self.train_Y = np.load(self.train_Y_preprocessed_data)\n",
        "        \n",
        "        self.dev_X = np.load(self.dev_X_preprocessed_data)\n",
        "        self.dev_Y = np.load(self.dev_Y_preprocessed_data)\n",
        "\n",
        "        self.test_X = np.load(self.test_X_preprocessed_data)\n",
        "        self.test_Y = np.load(self.test_Y_preprocessed_data)\n",
        "    \n",
        "\n",
        "    def precompute_min_timeseries_len(self):\n",
        "        for file in self.all_files_list:\n",
        "            print(\"Loading \" + str(file))\n",
        "            y, sr = librosa.load(file)\n",
        "            self.timeseries_length_list.append(math.ceil(len(y) / self.hop_length))\n",
        "\n",
        "    def extract_audio_features(self, list_of_audiofiles):\n",
        "\n",
        "        features = np.zeros(\n",
        "        (len(list_of_audiofiles)*9,self.timeseries_length,128,1), dtype=np.float64\n",
        "        )\n",
        "        target = []\n",
        "        c=0\n",
        "        for i, file in enumerate(list_of_audiofiles):\n",
        "          for j in range(9):\n",
        "            y, sr = librosa.load(file,offset= j*3 ,duration=6)\n",
        "            mfcc = librosa.feature.mfcc(\n",
        "                y=y, sr=sr, hop_length=self.hop_length, n_mfcc=20\n",
        "            )\n",
        "            spectral_center = librosa.feature.spectral_centroid(\n",
        "                y=y, sr=sr, hop_length=self.hop_length\n",
        "            )\n",
        "            chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=self.hop_length)\n",
        "            spectral_contrast = librosa.feature.spectral_contrast(\n",
        "                y=y, sr=sr, hop_length=self.hop_length\n",
        "            )\n",
        "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "            zcr = librosa.feature.zero_crossing_rate(y)\n",
        "            X = librosa.stft(y)\n",
        "            X = librosa.amplitude_to_db(abs(X))\n",
        "            spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "            spect = librosa.power_to_db(spect, ref=np.max)\n",
        "            if spect.shape[1] != 128:\n",
        "                spect.resize(128,128, refcheck=False)\n",
        "            if X.shape[1] != 128:\n",
        "               X.resize((128,128), refcheck=False)\n",
        "            splits = re.split(\"[ .]\", file)\n",
        "            genre = re.split(\"[ /]\", splits[1])[3]\n",
        "            target.append(genre)\n",
        "            print(genre)\n",
        "            features[c, :, 0:128,0]= X\n",
        "            \n",
        "            \n",
        "            c=c+1\n",
        "            print(\n",
        "                \"Extracted features audio track %i of %i.\"\n",
        "                % (c + 1, len(list_of_audiofiles)*10)\n",
        "            )\n",
        "        return features, np.expand_dims(np.asarray(target), axis=1)\n",
        "\n",
        "    def one_hot(self, Y_genre_strings):\n",
        "        y_one_hot = np.zeros((Y_genre_strings.shape[0],10))\n",
        "        for i, genre_string in enumerate(Y_genre_strings):\n",
        "            index = self.genre_list.index(genre_string)\n",
        "            y_one_hot[i,index] = 1 \n",
        "        return y_one_hot\n",
        "\n",
        "    @staticmethod\n",
        "    def path_to_audiofiles(dir_folder):\n",
        "        list_of_audio = []\n",
        "        for file in os.listdir(dir_folder):\n",
        "            if file.endswith(\".au\"):\n",
        "                directory = \"%s/%s\" % (dir_folder, file)\n",
        "                list_of_audio.append(directory)\n",
        "        return list_of_audio\n",
        "class wor1:\n",
        "\n",
        "    \"Music audio features for genre classification\"\n",
        "    hop_length = None\n",
        "    genre_list = [\n",
        "        \"blues\",\n",
        "        \"classical\",\n",
        "        \"country\",\n",
        "        \"disco\",\n",
        "        \"hiphop\",\n",
        "        \"jazz\",\n",
        "        \"metal\",\n",
        "        \"pop\",\n",
        "        \"reggae\",\n",
        "        \"rock\"\n",
        "    ]\n",
        "\n",
        "    dir_trainfolder = \"/content/drive/My Drive/samsung/train\"\n",
        "    dir_devfolder = \"/content/drive/My Drive/samsung/validation\"\n",
        "    dir_testfolder = \"/content/drive/My Drive/samsung/test\"\n",
        "    dir_all_files = \"/content/drive/My Drive/samsung\"\n",
        "\n",
        "    train_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dm6_train_input1.npy\"\n",
        "    train_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dm6_train_target1.npy\"\n",
        "    dev_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dm6_validation_input1.npy\"\n",
        "    dev_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dm6_validation_target1.npy\"\n",
        "    test_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dm6_test_input1.npy\"\n",
        "    test_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/dm6_test_target1.npy\"\n",
        "    train_X = train_Y = None\n",
        "    dev_X = dev_Y = None\n",
        "    test_X = test_Y = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.hop_length = 1024\n",
        "\n",
        "        self.timeseries_length_list = []\n",
        "        self.trainfiles_list = self.path_to_audiofiles(self.dir_trainfolder)\n",
        "        self.devfiles_list = self.path_to_audiofiles(self.dir_devfolder)\n",
        "        self.testfiles_list = self.path_to_audiofiles(self.dir_testfolder)\n",
        "\n",
        "        self.all_files_list = []\n",
        "        self.all_files_list.extend(self.trainfiles_list)\n",
        "        self.all_files_list.extend(self.devfiles_list)\n",
        "        self.all_files_list.extend(self.testfiles_list)\n",
        "\n",
        "        # compute minimum timeseries length, slow to compute, caching pre-computed value of 1290\n",
        "        # self.precompute_min_timeseries_len()\n",
        "        # print(\"min(self.timeseries_length_list) ==\" + str(min(self.timeseries_length_list)))\n",
        "        # self.timeseries_length = min(self.timeseries_length_list)\n",
        "\n",
        "        self.timeseries_length = (\n",
        "            128\n",
        "        )   # sequence length == 128, default fftsize == 2048 & hop == 512 @ SR of 22050\n",
        "        #  equals 128 overlapped windows that cover approx ~3.065 seconds of audio, which is a bit small!\n",
        "\n",
        "    def load_preprocess_data(self):\n",
        "        print(\"[DEBUG] total number of files: \" + str(len(self.timeseries_length_list)))\n",
        "\n",
        "        # Training set\n",
        "        self.train_X, self.train_Y = self.extract_audio_features(self.trainfiles_list)\n",
        "        with open(self.train_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.train_X)\n",
        "        with open(self.train_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.train_Y = self.one_hot(self.train_Y)\n",
        "            np.save(f, self.train_Y)\n",
        "\n",
        "        # Validation set\n",
        "        self.dev_X, self.dev_Y = self.extract_audio_features(self.devfiles_list)\n",
        "        with open(self.dev_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.dev_X)\n",
        "        with open(self.dev_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.dev_Y = self.one_hot(self.dev_Y)\n",
        "            np.save(f, self.dev_Y)\n",
        "\n",
        "        # Test set\n",
        "        self.test_X, self.test_Y = self.extract_audio_features(self.testfiles_list)\n",
        "        with open(self.test_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.test_X)\n",
        "        with open(self.test_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.test_Y = self.one_hot(self.test_Y)\n",
        "            np.save(f, self.test_Y)\n",
        "\n",
        "    def load_deserialize_data(self):\n",
        "\n",
        "        self.train_X = np.load(self.train_X_preprocessed_data)\n",
        "        self.train_Y = np.load(self.train_Y_preprocessed_data)\n",
        "\n",
        "        self.dev_X = np.load(self.dev_X_preprocessed_data)\n",
        "        self.dev_Y = np.load(self.dev_Y_preprocessed_data)\n",
        "\n",
        "        self.test_X = np.load(self.test_X_preprocessed_data)\n",
        "        self.test_Y = np.load(self.test_Y_preprocessed_data)\n",
        "    \n",
        "\n",
        "    def precompute_min_timeseries_len(self):\n",
        "        for file in self.all_files_list:\n",
        "            print(\"Loading \" + str(file))\n",
        "            y, sr = librosa.load(file)\n",
        "            self.timeseries_length_list.append(math.ceil(len(y) / self.hop_length))\n",
        "\n",
        "    def extract_audio_features(self, list_of_audiofiles):\n",
        "\n",
        "        features = np.zeros(\n",
        "        (len(list_of_audiofiles)*9,self.timeseries_length,128,1), dtype=np.float64\n",
        "        )\n",
        "        target = []\n",
        "        c=0\n",
        "        for i, file in enumerate(list_of_audiofiles):\n",
        "          for j in range(9):\n",
        "            y, sr = librosa.load(file,offset= j*3 ,duration=6)\n",
        "            mfcc = librosa.feature.mfcc(\n",
        "                y=y, sr=sr, hop_length=self.hop_length, n_mfcc=20\n",
        "            )\n",
        "            spectral_center = librosa.feature.spectral_centroid(\n",
        "                y=y, sr=sr, hop_length=self.hop_length\n",
        "            )\n",
        "            chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=self.hop_length)\n",
        "            spectral_contrast = librosa.feature.spectral_contrast(\n",
        "                y=y, sr=sr, hop_length=self.hop_length\n",
        "            )\n",
        "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "            zcr = librosa.feature.zero_crossing_rate(y)\n",
        "            X = librosa.stft(y)\n",
        "            X = librosa.amplitude_to_db(abs(X))\n",
        "            spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "            spect = librosa.power_to_db(spect, ref=np.max)\n",
        "            if spect.shape[1] != 128:\n",
        "                spect.resize(128,128, refcheck=False)\n",
        "            if X.shape[1] != 512:\n",
        "               X.resize((128,512), refcheck=False)\n",
        "            splits = re.split(\"[ .]\", file)\n",
        "            genre = re.split(\"[ /]\", splits[1])[3]\n",
        "            target.append(genre)\n",
        "            print(genre)\n",
        "            features[c, :, 0:128,0]= spect\n",
        "            \n",
        "            c=c+1\n",
        "            print(\n",
        "                \"Extracted features audio track %i of %i.\"\n",
        "                % (c + 1, len(list_of_audiofiles)*10)\n",
        "            )\n",
        "        return features, np.expand_dims(np.asarray(target), axis=1)\n",
        "\n",
        "    def one_hot(self, Y_genre_strings):\n",
        "        y_one_hot = np.zeros((Y_genre_strings.shape[0],10))\n",
        "        for i, genre_string in enumerate(Y_genre_strings):\n",
        "            index = self.genre_list.index(genre_string)\n",
        "            y_one_hot[i,index] = 1 \n",
        "        return y_one_hot\n",
        "\n",
        "    @staticmethod\n",
        "    def path_to_audiofiles(dir_folder):\n",
        "        list_of_audio = []\n",
        "        for file in os.listdir(dir_folder):\n",
        "            if file.endswith(\".au\"):\n",
        "                directory = \"%s/%s\" % (dir_folder, file)\n",
        "                list_of_audio.append(directory)\n",
        "        return list_of_audio\n",
        "class wor2:\n",
        "\n",
        "    \"Music audio features for genre classification\"\n",
        "    hop_length = None\n",
        "    genre_list = [\n",
        "        \"blues\",\n",
        "        \"classical\",\n",
        "        \"country\",\n",
        "        \"disco\",\n",
        "        \"hiphop\",\n",
        "        \"jazz\",\n",
        "        \"metal\",\n",
        "        \"pop\",\n",
        "        \"reggae\",\n",
        "        \"rock\"\n",
        "    ]\n",
        "\n",
        "    dir_trainfolder = \"/content/drive/My Drive/samsung/train\"\n",
        "    dir_devfolder = \"/content/drive/My Drive/samsung/validation\"\n",
        "    dir_testfolder = \"/content/drive/My Drive/samsung/test\"\n",
        "    dir_all_files = \"/content/drive/My Drive/samsung\"\n",
        "\n",
        "    train_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/mfe6_train_input1.npy\"\n",
        "    train_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/mfe6_train_target1.npy\"\n",
        "    dev_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/mfe6_validation_input1.npy\"\n",
        "    dev_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/mfe6_validation_target1.npy\"\n",
        "    test_X_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/mfe6_test_input1.npy\"\n",
        "    test_Y_preprocessed_data = \"/content/drive/My Drive/samsung/rb1/mfe6_test_target1.npy\"\n",
        "    train_X = train_Y = None\n",
        "    dev_X = dev_Y = None\n",
        "    test_X = test_Y = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.hop_length = 1024\n",
        "\n",
        "        self.timeseries_length_list = []\n",
        "        self.trainfiles_list = self.path_to_audiofiles(self.dir_trainfolder)\n",
        "        self.devfiles_list = self.path_to_audiofiles(self.dir_devfolder)\n",
        "        self.testfiles_list = self.path_to_audiofiles(self.dir_testfolder)\n",
        "\n",
        "        self.all_files_list = []\n",
        "        self.all_files_list.extend(self.trainfiles_list)\n",
        "        self.all_files_list.extend(self.devfiles_list)\n",
        "        self.all_files_list.extend(self.testfiles_list)\n",
        "\n",
        "        # compute minimum timeseries length, slow to compute, caching pre-computed value of 1290\n",
        "        # self.precompute_min_timeseries_len()\n",
        "        # print(\"min(self.timeseries_length_list) ==\" + str(min(self.timeseries_length_list)))\n",
        "        # self.timeseries_length = min(self.timeseries_length_list)\n",
        "\n",
        "        self.timeseries_length = (\n",
        "            128\n",
        "        )   # sequence length == 128, default fftsize == 2048 & hop == 512 @ SR of 22050\n",
        "        #  equals 128 overlapped windows that cover approx ~3.065 seconds of audio, which is a bit small!\n",
        "\n",
        "    def load_preprocess_data(self):\n",
        "        print(\"[DEBUG] total number of files: \" + str(len(self.timeseries_length_list)))\n",
        "\n",
        "        # Training set\n",
        "        self.train_X, self.train_Y = self.extract_audio_features(self.trainfiles_list)\n",
        "        with open(self.train_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.train_X)\n",
        "        with open(self.train_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.train_Y = self.one_hot(self.train_Y)\n",
        "            np.save(f, self.train_Y)\n",
        "\n",
        "        # Validation set\n",
        "        self.dev_X, self.dev_Y = self.extract_audio_features(self.devfiles_list)\n",
        "        with open(self.dev_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.dev_X)\n",
        "        with open(self.dev_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.dev_Y = self.one_hot(self.dev_Y)\n",
        "            np.save(f, self.dev_Y)\n",
        "\n",
        "        # Test set\n",
        "        self.test_X, self.test_Y = self.extract_audio_features(self.testfiles_list)\n",
        "        with open(self.test_X_preprocessed_data, \"wb\") as f:\n",
        "            np.save(f, self.test_X)\n",
        "        with open(self.test_Y_preprocessed_data, \"wb\") as f:\n",
        "            self.test_Y = self.one_hot(self.test_Y)\n",
        "            np.save(f, self.test_Y)\n",
        "\n",
        "    def load_deserialize_data(self):\n",
        "\n",
        "        self.train_X = np.load(self.train_X_preprocessed_data)\n",
        "        self.train_Y = np.load(self.train_Y_preprocessed_data)\n",
        "\n",
        "        self.dev_X = np.load(self.dev_X_preprocessed_data)\n",
        "        self.dev_Y = np.load(self.dev_Y_preprocessed_data)\n",
        "\n",
        "        self.test_X = np.load(self.test_X_preprocessed_data)\n",
        "        self.test_Y = np.load(self.test_Y_preprocessed_data)\n",
        "    \n",
        "\n",
        "    def precompute_min_timeseries_len(self):\n",
        "        for file in self.all_files_list:\n",
        "            print(\"Loading \" + str(file))\n",
        "            y, sr = librosa.load(file)\n",
        "            self.timeseries_length_list.append(math.ceil(len(y) / self.hop_length))\n",
        "\n",
        "    def extract_audio_features(self, list_of_audiofiles):\n",
        "\n",
        "        features = np.zeros(\n",
        "        (len(list_of_audiofiles)*9,128,13,1), dtype=np.float64\n",
        "        )\n",
        "        target = []\n",
        "        c=0\n",
        "        for i, file in enumerate(list_of_audiofiles):\n",
        "          for j in range(9):\n",
        "            y, sr = librosa.load(file,offset= j*3 ,duration=6)\n",
        "            mfcc = librosa.feature.mfcc(\n",
        "                y=y, sr=sr, hop_length=self.hop_length, n_mfcc=13\n",
        "            )\n",
        "            spectral_center = librosa.feature.spectral_centroid(\n",
        "                y=y, sr=sr, hop_length=self.hop_length\n",
        "            )\n",
        "            chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=self.hop_length)\n",
        "            spectral_contrast = librosa.feature.spectral_contrast(\n",
        "                y=y, sr=sr, hop_length=self.hop_length\n",
        "            )\n",
        "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "            zcr = librosa.feature.zero_crossing_rate(y)\n",
        "            X = librosa.stft(y)\n",
        "            X = librosa.amplitude_to_db(abs(X))\n",
        "            spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "            spect = librosa.power_to_db(spect, ref=np.max)\n",
        "            if spect.shape[1] != 128:\n",
        "                spect.resize(128,128, refcheck=False)\n",
        "            if X.shape[1] != 512:\n",
        "               X.resize((128,512), refcheck=False)\n",
        "            \n",
        "            splits = re.split(\"[ .]\", file)\n",
        "            genre = re.split(\"[ /]\", splits[1])[3]\n",
        "            target.append(genre)\n",
        "            print(genre)\n",
        "            features[c,:,0:13,0]=mfcc.T[0:128,:]\n",
        "            \n",
        "            c=c+1\n",
        "            print(\n",
        "                \"Extracted features audio track %i of %i.\"\n",
        "                % (c + 1, len(list_of_audiofiles)*10)\n",
        "            )\n",
        "        return features, np.expand_dims(np.asarray(target), axis=1)\n",
        "\n",
        "    def one_hot(self, Y_genre_strings):\n",
        "        y_one_hot = np.zeros((Y_genre_strings.shape[0],10))\n",
        "        for i, genre_string in enumerate(Y_genre_strings):\n",
        "            index = self.genre_list.index(genre_string)\n",
        "            y_one_hot[i,index] = 1 \n",
        "        return y_one_hot\n",
        "\n",
        "    @staticmethod\n",
        "    def path_to_audiofiles(dir_folder):\n",
        "        list_of_audio = []\n",
        "        for file in os.listdir(dir_folder):\n",
        "            if file.endswith(\".au\"):\n",
        "                directory = \"%s/%s\" % (dir_folder, file)\n",
        "                list_of_audio.append(directory)\n",
        "        return list_of_audio\n",
        "\n",
        "gen=wor()\n",
        "gen1=wor1()\n",
        "gen2=wor2()\n",
        "gen2.load_preprocess_data()\n",
        "#gen1.load_preprocess_data()\n",
        "gen.load_preprocess_data()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}